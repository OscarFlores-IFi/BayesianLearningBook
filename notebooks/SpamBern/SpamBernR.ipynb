{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analyzing email spam data with a Bernoulli model\n",
    "a notebook for the book [Bayesian Learning](https://github.com/mattiasvillani/BayesianLearningBook/raw/main/pdf/BayesBook.pdf) by [Mattias Villani](http://mattiasvillani.com)\n",
    "\n",
    "### Problem\n",
    "The SpamBase dataset from the [UCI repository](https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data) consists of $n=4601$ emails that \n",
    "have been manually classified as *spam* (junk email) or *ham* (non-junk email). \\\n",
    "The dataset also \n",
    "contains a vector of covariates/features for each email, such as the number of capital letters or \\$-signs; this information can be used to build a spam filter that automatically separates spam from ham.\\\n",
    "This notebook analyzes only the proportion of spam emails without using the covariates."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting started"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, load libraries and setting up colors."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "options(repr.plot.width=16, repr.plot.height=5, lwd = 4)\n",
    "library(\"RColorBrewer\") # for pretty colors\n",
    "library(\"tidyverse\")    # for string interpolation to print variables in plots.\n",
    "library(\"latex2exp\")    # the TeX() function makes it possible to print latex math\n",
    "colors = brewer.pal(12, \"Paired\")[c(1,2,7,8,3,4,5,6,9,10)];"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = read.csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\", sep=\",\", header = TRUE)\n",
    "spam = data$X1 # This is the binary data where spam = 1, ham = 0.\n",
    "n = length(spam)\n",
    "spam = sample(spam, size = n) # Randomly shuffle the data."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model, Prior and Posterior\n",
    "\n",
    "**Model**\n",
    "$$ X_1,\\ldots,X_n | \\theta \\sim \\mathrm{Bern}(\\theta)$$\n",
    "\n",
    "**Prior**\n",
    "$$\\theta\\sim\\mathrm{Beta}(\\alpha,\\beta)$$\n",
    "\n",
    "**Posterior**\n",
    "$$\\theta | x_1,\\ldots,x_n \\sim\\mathrm{Beta}(\\alpha+s,\\beta+f),$$\n",
    "\n",
    "where $s=\\sum_{i=1}^n$ is the number of 'successes' (spam) and $f=n-s$ is the number of 'failures' (ham)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us define a function that computes the posterior and plots it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "BernPost <- function(x, alphaPrior, betaPrior, legend = TRUE){\n",
    "    thetaGrid = seq(0,1, length = 1000)\n",
    "    n = length(x)\n",
    "    s = sum(x)\n",
    "    f = n - s\n",
    "    alphaPost = alphaPrior + s\n",
    "    betaPost = betaPrior + f\n",
    "    priorPDF = dbeta(thetaGrid, alphaPrior, betaPrior)\n",
    "    normLikePDF = dbeta(thetaGrid, s + 1, f + 1) # Trick to get the normalized likelihood\n",
    "    postPDF = dbeta(thetaGrid, alphaPost, betaPost)\n",
    "    \n",
    "    plot(1, type=\"n\", axes=FALSE, xlab = expression(theta), ylab = \"\", \n",
    "         xlim=c(min(thetaGrid),max(thetaGrid)), \n",
    "         ylim = c(0,max(priorPDF,postPDF,normLikePDF)), \n",
    "         main = TeX(sprintf(\"Prior: $\\\\mathrm{Beta}(\\\\alpha = %0.0f, \\\\beta = %0.0f)\", alphaPrior, betaPrior)))\n",
    "    axis(side = 1)\n",
    "    lines(thetaGrid, priorPDF, type = \"l\", lwd = 4, col = colors[6])\n",
    "    lines(thetaGrid, normLikePDF, lwd = 4, col = colors[2])\n",
    "    lines(thetaGrid, postPDF, lwd = 4, col = colors[4])\n",
    "    if (legend){\n",
    "        legend(x = \"topleft\", inset=.05,\n",
    "           legend = c(\"Prior\", \"Likelihood (normalized)\", \"Posterior\"),  \n",
    "           lty = c(1, 1, 1), pt.lwd = c(3, 3, 3), \n",
    "           col = c(colors[6], colors[2], colors[4]))\n",
    "    }\n",
    "    cat(\"Posterior mean is \", round(alphaPost/(alphaPost + betaPost),3), \"\\n\")\n",
    "    cat(\"Posterior standard deviation is \", round(sqrt(  alphaPost*betaPost/( (alphaPost+betaPost)^2*(alphaPost+betaPost+1))),3), \"\\n\")\n",
    "    return(list(\"alphaPost\" = alphaPrior + s, \"betaPost\" = betaPrior + f))\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let start by analyzing only the first 10 data points."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n = 10\n",
    "x = spam[1:n]\n",
    "par(mfrow = c(1,3))\n",
    "post = BernPost(x, alphaPrior = 1, betaPrior = 5, legend = TRUE)\n",
    "post = BernPost(x, alphaPrior = 5, betaPrior = 5, legend = FALSE)\n",
    "post = BernPost(x, alphaPrior = 5, betaPrior = 1, legend = FALSE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we only have $n=10$ data points, the posteriors for the three different priors differ a lot. Priors matter when the data are weak.\n",
    "Let's try with the $n=100$ first observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n = 100\n",
    "x = spam[1:n]\n",
    "par(mfrow = c(1,3))\n",
    "post = BernPost(x, alphaPrior = 1, betaPrior = 5, legend = TRUE)\n",
    "post = BernPost(x, alphaPrior = 5, betaPrior = 5, legend = FALSE)\n",
    "post = BernPost(x, alphaPrior = 5, betaPrior = 1, legend = FALSE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The effect of the prior is now almost gone. Finally let's use all $n=4601$ observations in the dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = spam\n",
    "par(mfrow = c(1,3))\n",
    "post = BernPost(x, alphaPrior = 1, betaPrior = 5, legend = TRUE)\n",
    "post = BernPost(x, alphaPrior = 5, betaPrior = 5, legend = FALSE)\n",
    "post = BernPost(x, alphaPrior = 5, betaPrior = 1, legend = FALSE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see two things:\n",
    "* The effect of the prior is completely gone. All three prior give identical posteriors. We have reached a subjective consensus among the three persons.\n",
    "* We are quite sure now that the spam probability $\\theta$ is around $0.4$.\n",
    "\n",
    "A later notebook will re-analyze this data using for example logistic regression."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}